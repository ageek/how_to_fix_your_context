{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Context Offloading\n\n## Background from Drew's Post\n\nContext offloading involves storing information outside the LLM's primary context to create a \"scratchpad\" for notes and intermediate thinking. Drew Breunig highlights Anthropic's research on this technique:\n\n- **Anthropic's \"think\" tool** serves as a scratchpad for complex reasoning\n- **Performance improvements up to 54%** in certain scenarios\n- **Useful for tool output analysis, policy-heavy environments, and sequential decision making**\n- **Reduces primary context load** while maintaining access to important information\n\nKey insights from Drew's research:\n- External scratchpads allow agents to save useful information during sessions\n- Can be implemented as tool calls that write to files or as state object fields\n- Essential for managing complex multi-step processes\n- Helps maintain context quality while reducing token usage\n\n## Context Offloading in Practice\n\nWhen humans solve tasks, we take notes and remember things for future, related tasks. Agents are also gaining these capabilities! Note-taking via a \"[scratchpad](https://www.anthropic.com/engineering/claude-think-tool)\" is one approach to persist information while an agent is performing a task. The central idea is to save information outside of the context window so that it's available to the agent on-demand. [Anthropic's multi-agent researcher](https://www.anthropic.com/engineering/built-multi-agent-research-system) illustrates a clear example of this:\n\n> The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan.\n\nIt's worth noting that this scratchpad can be implemented in a few different ways. It could be a [tool call](https://www.anthropic.com/engineering/claude-think-tool) that [writes to a file](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem). It could also just be a field in a runtime [state object](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) that persists during the session. In either case, the intuition is clear: scratchpads let agents save useful information during a session to help them accomplish tasks.\n\n### Scratchpad writing in LangGraph\n\nLangGraph was designed with first-class support of both thread-scoped ([short-term](https://langchain-ai.github.io/langgraph/concepts/memory/#short-term-memory)) and [long-term memory](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory). Short-term memory uses [checkpointing](https://langchain-ai.github.io/langgraph/concepts/persistence/) to persist [agent state](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) across all steps of an agent session. This is extremely useful as s \"scratchpad\", allowing you to write information to state during agent execution and fetch it later as needed.\n\nThe state object in LangGraph serves as the central data structure that gets passed between nodes in your graph. You can decide the schema for this state object, but it's common to use a Python dictionary. The state acts as a shared scratchpad; each node can read from and write to specific fields. Let's create `TypedDict` a state object."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.pretty import pprint\n",
    "\n",
    "# Initialize console for rich formatting\n",
    "console = Console()\n",
    "\n",
    "# Define a graph state with two fields\n",
    "class State(TypedDict):\n",
    "    \"\"\"State schema for the joke generator workflow.\n",
    "    \n",
    "    Attributes:\n",
    "        topic: The topic for joke generation\n",
    "        joke: The generated joke content\n",
    "    \"\"\"\n",
    "    topic: str\n",
    "    joke: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## State-Based Scratchpads\n\nOnce we've defined a state object, we can use it as a scratchpad. A [StateGraph](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) is LangGraph's primary abstraction for building stateful workflows where each node can read from and modify shared state.\n\n**Key concepts:**\n- **Nodes** are processing steps that receive current state and return updates\n- **Edges** connect nodes to create execution flow (linear, conditional, or cyclical)\n- **State** serves as a shared scratchpad between nodes\n\nThe mechanism for selecting context depends on implementation:\n- **Tool-based**: Agent reads scratchpad via tool calls\n- **State-based**: Developer controls what state parts are exposed to agents\n\nThis provides fine-grained control over context presentation to LLM calls."
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.pretty import pprint\n",
    "\n",
    "# Initialize console for rich formatting\n",
    "console = Console()\n",
    "\n",
    "# Define a graph state with two fields\n",
    "class State(TypedDict):\n",
    "    \"\"\"State schema for the joke generator workflow.\n",
    "    \n",
    "    Attributes:\n",
    "        topic: The topic for joke generation\n",
    "        joke: The generated joke content\n",
    "    \"\"\"\n",
    "    topic: str\n",
    "    joke: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "\n",
    "def _set_env(var: str) -> None:\n",
    "    \"\"\"Set environment variable if not already set.\"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# Set up environment and initialize model\n",
    "_set_env(\"ANTHROPIC_API_KEY\")\n",
    "llm = init_chat_model(\"anthropic:claude-sonnet-4-20250514\", temperature=0)\n",
    "\n",
    "\n",
    "def generate_joke(state: State) -> dict[str, str]:\n",
    "    \"\"\"Generate an initial joke about the topic.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state containing the topic\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with the generated joke\n",
    "    \"\"\"\n",
    "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "\n",
    "def improve_joke(state: State) -> dict[str, str]:\n",
    "    \"\"\"Improve an existing joke by adding wordplay.\n",
    "    \n",
    "    This demonstrates selecting context from state - we read the existing\n",
    "    joke from state and use it to generate an improved version.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state containing the original joke\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with the improved joke\n",
    "    \"\"\"\n",
    "    print(f\"Initial joke: {state['joke']}\")\n",
    "    \n",
    "    # Select the joke from state to present it to the LLM\n",
    "    msg = llm.invoke(f\"Make this joke funnier by adding wordplay: {state['joke']}\")\n",
    "    return {\"improved_joke\": msg.content}\n",
    "\n",
    "\n",
    "# Build the workflow with two sequential nodes\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add both joke generation nodes\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "workflow.add_node(\"improve_joke\", improve_joke)\n",
    "\n",
    "# Connect nodes in sequence\n",
    "workflow.add_edge(START, \"generate_joke\")\n",
    "workflow.add_edge(\"generate_joke\", \"improve_joke\")\n",
    "workflow.add_edge(\"improve_joke\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "chain = workflow.compile()\n",
    "\n",
    "# Display the workflow visualization\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial joke: Why don't cats ever win races?\n",
      "\n",
      "Because they always paws right before the finish line!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Final Workflow State:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mFinal Workflow State:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m\"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute the workflow to see context selection in action\n",
    "joke_generator_state = chain.invoke({\"topic\": \"cats\"})\n",
    "\n",
    "# Display the final state with rich formatting\n",
    "console.print(\"\\n[bold blue]Final Workflow State:[/bold blue]\")\n",
    "pprint(joke_generator_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory \n",
    "\n",
    "Scratchpads helps agents solve a task within a given session, but sometimes agents benefit from remembering things across *many* sessions! [Reflexion](https://arxiv.org/abs/2303.11366) introduced the idea of reflection following each agent turn and re-using these self-generated hints. [Generative Agents](https://ar5iv.labs.arxiv.org/html/2304.03442) created memories synthesized periodically from collections of past agent feedback.\n",
    "\n",
    "These concepts made their way into popular products like [ChatGPT](https://help.openai.com/en/articles/8590148-memory-faq), [Cursor](https://forum.cursor.com/t/0-51-memories-feature/98509), and [Windsurf](https://docs.windsurf.com/windsurf/cascade/memories), which all have mechanisms to auto-generate long-term memories based on user-agent interactions.\n",
    "\n",
    "### Memory writing in LangGraph\n",
    "\n",
    "Checkpointing saves the state of your graph at each step. These are saved to a [thread](https://langchain-ai.github.io/langgraph/concepts/persistence/). Each thread is referenced by a unique identifier and typically represents a single interaction with an agent. It it analogous to a single \"chat thread\" with ChatGPT, for example.\n",
    "\n",
    "LangGraph’s long-term memory allows you to persist specific context *across threads* with your agent. It is flexible, allowing you to save [individual files](https://langchain-ai.github.io/langgraph/concepts/memory/#profile) (e.g., a user profile) or [collections](https://langchain-ai.github.io/langgraph/concepts/memory/#collection) of memories. \n",
    "\n",
    "LangGraph’s long-term memory uses the [BaseStore](https://langchain-ai.github.io/langgraph/reference/store/) interface, which is a key-value store. It can be use in memory, as we show below in this notebook. It also can be used with [LangGraph Platform deployments](https://langchain-ai.github.io/langgraph/concepts/persistence/#langgraph-platform).\n",
    "\n",
    "Let's create an `InMemoryStore` for use across a few different sessions in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize the in-memory store for long-term memory\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Define namespace as a tuple (user_id, application_context)\n",
    "namespace = (\"rlm\", \"joke_generator\")\n",
    "\n",
    "# Write context as a key-value pair to the namespace\n",
    "store.put(\n",
    "    namespace,                             # namespace for organizing data\n",
    "    \"last_joke\",                          # key for this specific piece of data\n",
    "    {\"joke\": joke_generator_state[\"joke\"]} # value to store\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll talk more about selecting context from the namespace in the next notebook.\n",
    "\n",
    "For now, we can just use the [search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search) to view items within a namespace and see that we wrote to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Retrieved Context from Memory:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mRetrieved Context from Memory:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m\"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select (retrieve) the joke from memory\n",
    "retrieved_joke = store.get(namespace, \"last_joke\").value\n",
    "\n",
    "# Display the retrieved context\n",
    "console.print(\"\\n[bold green]Retrieved Context from Memory:[/bold green]\")\n",
    "pprint(retrieved_joke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's just embed what we did inside a LangGraph workflow.\n",
    "\n",
    "We compile our workflow with two arguments: \n",
    "\n",
    "* `checkpointer`: Save graph state at each step to a thread \n",
    "* `store`: Persist context across threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize storage components\n",
    "checkpointer = InMemorySaver()\n",
    "memory_store = InMemoryStore()\n",
    "\n",
    "\n",
    "def generate_joke(state: State, store: BaseStore) -> dict[str, str]:\n",
    "    \"\"\"Generate a joke with memory-aware context selection.\n",
    "    \n",
    "    This function demonstrates selecting context from memory before\n",
    "    generating new content, ensuring consistency and avoiding duplication.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state containing the topic\n",
    "        store: Memory store for persistent context\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with the generated joke\n",
    "    \"\"\"\n",
    "    # Select prior joke from memory if it exists\n",
    "    prior_joke = store.get(namespace, \"last_joke\")\n",
    "    if prior_joke:\n",
    "        prior_joke_text = prior_joke.value[\"joke\"]\n",
    "        print(f\"Prior joke: {prior_joke_text}\")\n",
    "    else:\n",
    "        print(\"Prior joke: None!\")\n",
    "\n",
    "    # Generate a new joke that differs from the prior one\n",
    "    prompt = (\n",
    "        f\"Write a short joke about {state['topic']}, \"\n",
    "        f\"but make it different from any prior joke you've written: {prior_joke_text if prior_joke else 'None'}\"\n",
    "    )\n",
    "    msg = llm.invoke(prompt)\n",
    "\n",
    "    # Store the new joke in memory for future context selection\n",
    "    store.put(namespace, \"last_joke\", {\"joke\": msg.content})\n",
    "\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "\n",
    "# Build the memory-aware workflow\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "\n",
    "# Connect the workflow\n",
    "workflow.add_edge(START, \"generate_joke\")\n",
    "workflow.add_edge(\"generate_joke\", END)\n",
    "\n",
    "# Compile with both checkpointing and memory store\n",
    "chain = workflow.compile(checkpointer=checkpointer, store=memory_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior joke: None!\n"
     ]
    }
   ],
   "source": [
    "# Execute the workflow with the first thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing joke: No existing joke\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Workflow Result (Thread </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">):</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mWorkflow Result \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36mThread \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m)\u001b[0m\u001b[1;36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m\"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute the workflow with thread-based configuration\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)\n",
    "\n",
    "# Display the workflow result with rich formatting\n",
    "console.print(\"\\n[bold cyan]Workflow Result (Thread 1):[/bold cyan]\")\n",
    "pprint(joke_generator_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we compiled with a checkpointer, we can see the [latest state](https://langchain-ai.github.io/langgraph/concepts/persistence/#get-state) of the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Latest Graph State:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35mLatest Graph State:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StateSnapshot</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">values</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Why don't cats ever win at poker?\\n\\nBecause they can't help but purr when they have a good hand!\"</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">next</span>=<span style=\"font-weight: bold\">()</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'configurable'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'thread_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_ns'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1f0636ed-67fc-6fca-8001-47c4eca91406'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'loop'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'step'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'parents'</span>: <span style=\"font-weight: bold\">{}}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-18T00:33:34.473820+00:00'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">parent_config</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'configurable'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'thread_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_ns'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'checkpoint_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1f0636ed-4ffc-61c8-8000-121bc404e313'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">tasks</span>=<span style=\"font-weight: bold\">()</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">interrupts</span>=<span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mStateSnapshot\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mvalues\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m\"Why don't cats ever win at poker?\\n\\nBecause they can't help but purr when they have a good hand!\"\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mnext\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mconfig\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'configurable'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'thread_id'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_ns'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_id'\u001b[0m: \u001b[32m'1f0636ed-67fc-6fca-8001-47c4eca91406'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'loop'\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'parents'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mcreated_at\u001b[0m=\u001b[32m'2025-07-18T00:33:34.473820+00:00'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mparent_config\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'configurable'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'thread_id'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_ns'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'checkpoint_id'\u001b[0m: \u001b[32m'1f0636ed-4ffc-61c8-8000-121bc404e313'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mtasks\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33minterrupts\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the latest state of the graph\n",
    "latest_state = chain.get_state(config)\n",
    "\n",
    "console.print(\"\\n[bold magenta]Latest Graph State:[/bold magenta]\")\n",
    "pprint(latest_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing joke: {'joke': \"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Workflow Result (Thread </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">):</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33mWorkflow Result \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mThread \u001b[0m\u001b[1;33m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cats'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'joke'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'topic'\u001b[0m: \u001b[32m'cats'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'joke'\u001b[0m: \u001b[32m\"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute the workflow with a different thread ID\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)\n",
    "\n",
    "# Display the result showing memory persistence across threads\n",
    "console.print(\"\\n[bold yellow]Workflow Result (Thread 2):[/bold yellow]\")\n",
    "pprint(joke_generator_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch the prior joke from memory and pass it to an LLM to improve it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior joke: Why don't cats ever win at poker?\n",
      "\n",
      "Because they can't help but purr when they have a good hand!\n"
     ]
    }
   ],
   "source": [
    "# Execute the workflow with a second thread to demonstrate memory persistence\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}